{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "The dash_html_components package is deprecated. Please replace\n",
      "`import dash_html_components as html` with `from dash import html`\n",
      "\n",
      "The dash_core_components package is deprecated. Please replace\n",
      "`import dash_core_components as dcc` with `from dash import dcc`\n",
      "\n",
      "The dash_table package is deprecated. Please replace\n",
      "`import dash_table` with `from dash import dash_table`\n",
      "\n",
      "Also, if you're using any of the table format helpers (e.g. Group), replace \n",
      "`from dash_table.Format import Group` with \n",
      "`from dash.dash_table.Format import Group`\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import StackingClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.general_utils import load_data_old, get_cat_feature_names\n",
    "from utils.model_extensions_utils import FocalLossObjective\n",
    "from utils.plot_utils import Evaluation\n",
    "# from utils.fe_utils import get_growth_features\n",
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard, InlineExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from utils.fe_utils import get_growth_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def process_df(X_temp):\n",
    "    # - remove zero variance features\n",
    "    # cols_to_drop = [col for col in X_temp.select_dtypes(include=np.number).columns if np.std(X_temp[col]) == 0]\n",
    "    # X_temp = X_temp.drop(cols_to_drop, axis=1)\n",
    "    tech_cols = ['maven', 'generic', 'docker', 'npm', 'pypi', 'gradle', 'nuget']\n",
    "    usage_cols = tech_cols + ['artifacts_count', 'artifacts_size', 'binaries_count', 'binaries_size', 'items_count',\n",
    "                              'number_of_permissions', 'internal_groups', 'number_of_users', 'n_env', 'n_tech',\n",
    "                              'n_repos']\n",
    "    X_temp['n_tech'] = (X_temp[tech_cols] != 0).astype(int).sum(axis=1)\n",
    "    X_temp['n_tech.1'] = (X_temp[[col + '.1' for col in tech_cols]] != 0).astype(int).sum(axis=1)\n",
    "    X_temp['n_tech.2'] = (X_temp[[col + '.2' for col in tech_cols]] != 0).astype(int).sum(axis=1)\n",
    "    X_temp['n_tech.3'] = (X_temp[[col + '.3' for col in tech_cols]] != 0).astype(int).sum(axis=1)\n",
    "    X_temp['n_tech.4'] = (X_temp[[col + '.4' for col in tech_cols]] != 0).astype(int).sum(axis=1)\n",
    "    X_temp['n_repos'] = (X_temp[tech_cols]).sum(axis=1)\n",
    "    X_temp['n_repos.1'] = (X_temp[[col + '.1' for col in tech_cols]]).sum(axis=1)\n",
    "    X_temp['n_repos.2'] = (X_temp[[col + '.2' for col in tech_cols]]).sum(axis=1)\n",
    "    X_temp['n_repos.3'] = (X_temp[[col + '.3' for col in tech_cols]]).sum(axis=1)\n",
    "    X_temp['n_repos.4'] = (X_temp[[col + '.4' for col in tech_cols]]).sum(axis=1)\n",
    "    # X_temp['leading_tech'] = list(X_temp[tech_cols].idxmax(axis=1))\n",
    "    # X_temp.loc[X_temp['leading_tech'].isin(['npm', 'gradle', 'pypi']), 'leading_tech'] = 'else'\n",
    "\n",
    "    # - get trends features\n",
    "    for col in usage_cols:\n",
    "        growth_feature_monthly, growth_feature_quarter, df_fg = get_growth_features(col, X_temp.copy())\n",
    "        X_temp[col + '_monthly_growth'] = growth_feature_monthly\n",
    "        X_temp[col + '_quarter_growth'] = growth_feature_quarter\n",
    "\n",
    "\n",
    "    # - transform to category\n",
    "    cat_features = get_cat_feature_names(X_temp)\n",
    "    for col in cat_features:\n",
    "        X_temp[col] = X_temp[col].astype('category')\n",
    "\n",
    "    # - drop usage features from the periods before the relevant-date\n",
    "    cols_to_drop = [col for col in X_temp.columns if '.1' in col or '.2' in col or '.3' in col or '.4' in col]\n",
    "    X_temp = X_temp.drop(cols_to_drop, axis=1)\n",
    "    X_temp['artifacts/binaries_size'] = np.where(X_temp['binaries_size'] == 0, 0, X_temp['artifacts_size'] / X_temp['binaries_size'])\n",
    "    X_temp['artifacts/binaries_count'] = np.where(X_temp['binaries_count'] == 0, 0, X_temp['artifacts_count'] / X_temp['binaries_count'])\n",
    "    X_temp = X_temp.drop(['total_employees_with_details', 'days_from_contact_added', 'territory', 'industry_group',\n",
    "                          'total_employees_range'], axis=1)\n",
    "    return X_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "consolidate_opps = True\n",
    "df = load_data_old('fit.sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "if consolidate_opps:\n",
    "    has_won = df.groupby('account_id', as_index=False).sum('class').loc[:, ['account_id', 'class']]\n",
    "    has_won['has_won'] = has_won['class'].apply(lambda x: True if x > 0 else False)\n",
    "    has_won.drop('class', axis=1, inplace=True)\n",
    "    new_df = df.merge(has_won, on='account_id')\n",
    "    df_did_win, df_did_not_win = new_df[new_df['has_won']], new_df[~new_df['has_won']]\n",
    "    df_did_win = df_did_win[df_did_win['class'] == 1].groupby('account_id', as_index=False).min('relevant_date')\n",
    "    df_did_not_win = df_did_not_win.groupby('account_id').sample(n=1, random_state=2)\n",
    "    df = pd.concat([df_did_win, df_did_not_win])\n",
    "    df = df.sample(frac=1, random_state=2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "cols_to_drop = [col for col in df.columns if 'period_range' in col or 'relevant_date' in col or 'account_id' in col\n",
    "                or 'class' in col or 'has_won' in col]\n",
    "X, y = df.drop(cols_to_drop, axis=1).fillna(-1), df['class']\n",
    "X = process_df(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(len(X.columns))\n",
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "eval = Evaluation()\n",
    "cbc = CatBoostClassifier(cat_features=get_cat_feature_names(X), auto_class_weights='Balanced', verbose=0,\n",
    "                         random_state=5, loss_function=FocalLossObjective(), eval_metric=\"Logloss\", bootstrap_type='Bayesian')\n",
    "lgb = LGBMClassifier(class_weight='balanced', random_state=5)\n",
    "clfs = [('catboost', cbc), ('lightgbm', lgb)]\n",
    "stacking = StackingClassifier(estimators=clfs, final_estimator=LogisticRegression(class_weight='balanced'))\n",
    "feature_importance = eval.plot_cv_precision_recall(clf=cbc, n_folds=5, n_repeats=1, X=X, y=y, stacking=False,\n",
    "                                              random_state=2, threshold=0.25)\n",
    "eval.plot_feature_importance(feature_importance.copy(), n_features_to_show=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_for_predict = load_data_old('predict.sql')\n",
    "cols_to_drop = [col for col in df_for_predict.columns if 'period_range' in col or 'relevant_date' in col or 'account_id' in col\n",
    "                or 'class' in col or 'has_won' in col]\n",
    "df_for_predict_clean = df_for_predict.drop(cols_to_drop, axis=1)\n",
    "df_for_predict_clean = process_df(df_for_predict_clean)\n",
    "df_for_predict_clean['class_pred_proba'] = cbc.predict_proba(df_for_predict_clean)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_for_predict_clean"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_for_predict_clean['class_pred'] = df_for_predict_clean['class_pred_proba'].apply(lambda x: 1 if x >= 0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "np.sum(df_for_predict_clean['class_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cbc.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "explainer = ClassifierExplainer(cbc, X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ExplainerDashboard(explainer).run()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "shap_values = shap.TreeExplainer(cbc).shap_values(df_for_predict_clean)\n",
    "shap.summary_plot(shap_values, df_for_predict_clean, plot_type=\"bar\")\n",
    "f = plt.figure()\n",
    "shap.summary_plot(shap_values, df_for_predict_clean)\n",
    "# f.savefig(\"/summary_plot1.png\", bbox_inches='tight', dpi=600)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_for_predict_clean['account_id'] = df_for_predict['account_id']\n",
    "df_for_predict_clean.loc[df_for_predict_clean['class_pred'] == 1,'account_id'].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(\"ih\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}